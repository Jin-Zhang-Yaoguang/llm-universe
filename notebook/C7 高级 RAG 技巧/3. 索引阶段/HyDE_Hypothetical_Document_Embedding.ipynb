{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理论介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HyDE 是一种创新方法，它将查询问题转换为包含答案的假设文档，旨在弥合向量空间中查询和文档分布之间的差距。传统的检索方法通常难以解决短查询和更长、更详细的文档之间的语义差距。HyDE 通过将查询扩展为完整的假设文档来解决这个问题，通过使查询表示更类似于向量空间中的文档表示，可能提高检索相关性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HyDE实现过程](figures/HyDE.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现步骤\n",
    "1. PDF 处理和文本分块\n",
    "2. 文档向量话：使用 Chroma 和 embedding 模型创建向量存储\n",
    "3. 用于生成假设文档的语言模型：\n",
    "    - 使用LL生成回答给定查询的假设文档。\n",
    "    - 生成过程由提示模板引导，确保假设文档详细且与向量存储中使用的块大小相匹配。\n",
    "4. 检索过程：基于 HyDE 技术实现自定义 HyDERetriever 类\n",
    "    - 使用语言模型根据查询生成假设文档。\n",
    "    - 使用假设文档作为向量存储中的搜索查询。\n",
    "    - 检索与该假设文档最相似的文档块。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法优点：\n",
    "1. 提高相关性：通过将查询扩展到完整文档，HyDE 可以捕获更细致和相关的匹配\n",
    "2. 处理复杂查询：对于可能难以直接匹配的复杂或多方面查询特别有用。\n",
    "3. 提升跨领域属于理解：假设的文档生成可以适应不同类型的查询和文档领域。\n",
    "4. 更好地理解上下文：扩展的查询可能会更好地捕获原始问题背后的上下文和意图。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"data/pumpkin_book.pdf\"\n",
    "qa_path = 'data/train_dataset.json'\n",
    "embedding = HuggingFaceEmbeddings(model_name='BAAI/bge-small-zh-v1.5')\n",
    "\n",
    "with open(qa_path, 'r', encoding='utf-8') as file:\n",
    "    qa_pairs = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str):\n",
    "    \"\"\"\n",
    "    实现文本清理函数\n",
    "\n",
    "    参数:\n",
    "        text: 需要清理的字段\n",
    "\n",
    "    返回:\n",
    "        清理完成后返回的字段\n",
    "    \n",
    "    \"\"\"\n",
    "    # 删除每页开头与结尾标语及链接\n",
    "    text = re.sub(r'→_→\\n欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解》\\n←_←', '', text)\n",
    "    text = re.sub(r'→_→\\n配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\\n←_←', '', text)\n",
    "    # 删除字符串开头的空格\n",
    "    text = re.sub(r'\\s+', '', text)\n",
    "    # 删除回车\n",
    "    text = re.sub(r'\\n+', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def encode_pdf(path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    使用 OpenAI 嵌入将 PDF 书籍编码为向量存储。\n",
    "\n",
    "    参数:\n",
    "        path: PDF 文件的路径。\n",
    "        chunk_size: 每个文本块的期望大小。\n",
    "        chunk_overlap: 连续块之间的重叠量。\n",
    "\n",
    "    返回:\n",
    "        包含内容的向量存储。\n",
    "    \"\"\"\n",
    "\n",
    "    # 创建一个 PyMuPDFLoader Class 实例，输入为待加载的 pdf 文档路径，加载PDF\n",
    "    loader = PyMuPDFLoader(path)\n",
    "    \n",
    "    # 调用 PyMuPDFLoader Class 的函数 load 对 pdf 文件进行加载\n",
    "    pdf_pages = loader.load()\n",
    "    \n",
    "    # 第13页为南瓜书第一页正文，因此从13页开始,从倒数13页涉及敏感用语，因此从-13页结束\n",
    "    data_pages = pdf_pages[13:-13]\n",
    "\n",
    "    for page in data_pages:\n",
    "        page.page_content = clean_text(page.page_content)\n",
    "\n",
    "    # 文档分块\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, separator='')\n",
    "\n",
    "    split_docs = text_splitter.split_documents(data_pages)\n",
    "\n",
    "\n",
    "    # 构建向量库\n",
    "    vectordb = Chroma.from_documents(documents=split_docs, embedding=embedding)\n",
    "\n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 功能实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyDERetriever:\n",
    "    def __init__(self, chunk_size=400, chunk_overlap=50):\n",
    "        self.llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
    "        self.embeddings = embedding\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.hyde_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"chunk_size\"],\n",
    "            template=\"\"\"给定问题\"{query}\"，生成一个直接回答该问题的假想文档。该文档应详细且深入，其长度必须正好为\"{chunk_size}\"个字符。\"\"\"\n",
    "        )\n",
    "        self.hyde_chain = self.hyde_prompt | self.llm\n",
    "\n",
    "    # 基于pdf构建向量数据库    \n",
    "    def encode_pdf_to_vectorstore(self, files_path):\n",
    "        self.vectorstore = encode_pdf(files_path, chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap)\n",
    "\n",
    "    # 生成假设问题\n",
    "    def generate_hypothetical_document(self, query):\n",
    "        input_variables = {\"query\": query, \"chunk_size\": self.chunk_size}\n",
    "        return self.hyde_chain.invoke(input_variables).content\n",
    "\n",
    "    # 就要假设问题召回top5\n",
    "    def retrieve(self, query, k=5):\n",
    "        hypothetical_doc = self.generate_hypothetical_document(query)\n",
    "        similar_docs = self.vectorstore.similarity_search(hypothetical_doc, k=k)\n",
    "        return similar_docs, hypothetical_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = HyDERetriever()\n",
    "retriever.encode_pdf_to_vectorstore(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '请根据提供的上下文信息，解释什么是“泛化”能力，并给出一个具体的例子说明为何泛化能力是衡量机器学习模型好坏的关键。',\n",
       " 'answer': '泛化：由于机器学习的目标是根据已知来对未知做出尽可能准确的判断，因此对未知事物判断的准确与否才是衡量一个模型好坏的关键，我们称此为“泛化”能力。例如学习西瓜好坏时，假设训练集中共有3个样本：{(x1=(青绿;蜷缩),y1=好瓜),(x2=(乌黑;蜷缩),y2=好瓜),(x3=(浅白;蜷缩),y3=好瓜)}，同时假设判断西瓜好坏的真相是“只要根蒂蜷缩就是好瓜”，如果应用算法A在此训练集上训练得到模型fa(x)，模型a学到的规律是“色泽等于青绿、乌黑或者浅白时，同时根蒂蜷缩即为好瓜，否则便是坏瓜”，再应用算法B在此训练集上训练得到模型fb(x)，模型fb(x)学到的规律是“只要根蒂蜷缩就是好瓜”，因此对于一个未见过的西瓜样本x=(金黄;蜷缩)来说，模型fa(x)给出的预测结果为“坏瓜”，模型fb(x)给出的预测结果为“好瓜”，此时我们称模型fb(x)的泛化能力优于模型fa(x)。通过以上举例可知，尽管模型fa(x)和模型fb(x)对训练集学得一样好，即两个模型对训练集中每个样本的判断都对，但是其所学到的规律是不同的。导致此现象最直接的原因是算法的不同，但是算法通常是有限的，可穷举的，尤其是在特定任务场景下可使用的算法更是有限，因此，数据便是导致此现象的另一重要原因，这也就是机器学习领域常说的“数据决定模型的上限，而算法则是让模型无限逼近上限”。',\n",
       " 'page_num': 14}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doc = 1\n",
    "\n",
    "qa_pairs[test_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = qa_pairs[test_doc]['query']\n",
    "results, hypothetical_doc = retriever.retrieve(test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'泛化能力是指机器学习模型在未见过的数据上表现良好的能力。它衡量模型是否能从训练数据中学到普遍规律，而非仅仅记住训练样本。泛化能力是模型好坏的关键，因为过拟合模型在训练集上表现优异，但在新数据上效果差。举例来说，垃圾邮件过滤器若具备良好泛化能力，能准确识别新型垃圾邮件，而非仅识别训练时见过的邮件。泛化能力确保模型在真实世界中具备实用性和可靠性。'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothetical_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': 'data/pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 17, 'producer': 'xdvipdfmx (20200315)', 'source': 'data/pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}, page_content='。泛化误差：学习器在新样本上的误差。经验误差和泛化误差用于分类问题的定义式可参见“西瓜书”第12章的式(12.1)和式(12.2)，接下来辨析一下以上几个概念。错误率和精度很容易理解，而且很明显是针对分类问题的。误差的概念更适用于回归问题，但是，根据“西瓜书”第12章的式(12.1)和式(12.2)的定义可以看出，在分类问题中也会使用误差的概念，此时的“差异”指的是学习器的实际预测输出的类别与样本真实的类别是否一致，若一致则“差异”为0，若不一致则“差异”为1，训练误差是在训练集上差异的平均值，而泛化误差则是在新样本（训练集中未出现过的样本）上差异的平均值。过拟合是由于模型的学习能力相对于数据来说过于强大，反过来说，欠拟合是因为模型的学习能力相对于数据来说过于低下。暂且抛开“没有免费的午餐”定理不谈，例如对于“西瓜书”第1章图1.4中的训练样本（黑点）来说，用类似于抛物线的曲线A去拟合则较为合理，而比较崎岖的曲线B相对于训练样本来说学习能力过于强大，但若仅用一条直线去训练则相对于训练样本来说直线的学习能力过于低下。2.2评估方法本节介绍了3种模型评估方法：留出法、交叉验证法、自助法。留'),\n",
       " Document(metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': 'data/pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 17, 'producer': 'xdvipdfmx (20200315)', 'source': 'data/pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}, page_content='学习器的实际预测输出与样本的真实输出之间的差异。经验误差：学习器在训练集上的误差，又称为“训练误差”。泛化误差：学习器在新样本上的误差。经验误差和泛化误差用于分类问题的定义式可参见“西瓜书”第12章的式(12.1)和式(12.2)，接下来辨析一下以上几个概念。错误率和精度很容易理解，而且很明显是针对分类问题的。误差的概念更适用于回归问题，但是，根据“西瓜书”第12章的式(12.1)和式(12.2)的定义可以看出，在分类问题中也会使用误差的概念，此时的“差异”指的是学习器的实际预测输出的类别与样本真实的类别是否一致，若一致则“差异”为0，若不一致则“差异”为1，训练误差是在训练集上差异的平均值，而泛化误差则是在新样本（训练集中未出现过的样本）上差异的平均值。过拟合是由于模型的学习能力相对于数据来说过于强大，反过来说，欠拟合是因为模型的学习能力相对于数据来说过于低下。暂且抛开“没有免费的午餐”'),\n",
       " Document(metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': 'data/pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 17, 'producer': 'xdvipdfmx (20200315)', 'source': 'data/pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}, page_content='第2章模型评估与选择如“西瓜书”前言所述，本章仍属于机器学习基础知识，如果说第1章介绍了什么是机器学习及机器学习的相关数学符号，那么本章则进一步介绍机器学习的相关概念。具体来说，介绍内容正如本章名称“模型评估与选择”所述，讲述的是如何评估模型的优劣和选择最适合自己业务场景的模型。由于“模型评估与选择”是在模型产出以后进行的下游工作，要想完全吸收本章内容需要读者对模型有一些基本的认知，因此零基础的读者直接看本章会很吃力，实属正常，在此建议零基础的读者可以简单泛读本章，仅看能看懂的部分即可，或者直接跳过本章从第3章开始看，直至看完第6章以后再回头来看本章便会轻松许多。2.1经验误差与过拟合梳理本节的几个概念。错误率：E=am，其中m为样本个数，a为分类错误样本个数。精度：精度=1-错误率。误差：学习器的实际预测输出与样本的真实输出之间的差异。经验误差：学习器在训练集上的误差，又称为“训练误差”。泛化误差：学习器在新样本上的误差。经验误差和泛化误差用于分类问题的定义式可参见“西瓜书”第12章的式(12.1)和式(12.2)，接下来辨析一下以上几个概念。错误率和精度很容易理解，而且很明显是针对'),\n",
       " Document(metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': 'data/pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 14, 'producer': 'xdvipdfmx (20200315)', 'source': 'data/pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}, page_content='x)对训练集学得一样好，即两个模型对训练集中每个样本的判断都对，但是其所学到的规律是不同的。导致此现象最直接的原因是算法的不同，但是算法通常是有限的，可穷举的，尤其是在特定任务场景下可使用的算法更是有限，因此，数据便是导致此现象的另一重要原因，这也就是机器学习领域常说的“数据决定模型的上限，而算法则是让模型无限逼近上限”,下面详细解释此话的含义。先解释“数据决定模型效果的上限”，其中数据是指从数据量和特征工程两个角度考虑。从数据量的角度来说，通常数据量越大模型效果越好，因为数据量大即表示累计的经验多，因此模型学习到的经验也多，自然表现效果越好。例如以上举例中如果训练集中含有相同颜色但根蒂不蜷缩的坏瓜，模型a学到真相的概率则也会增大；从特征工程的角度来说，通常对特征数值化越合理，特征收集越全越细致，模型效果通常越好，因为此时模型更易学得样本之间潜在的规律。例如学习区分亚洲人和非洲人时，此时样'),\n",
       " Document(metadata={'author': '', 'creationDate': \"D:20230303170709-00'00'\", 'creator': 'LaTeX with hyperref', 'file_path': 'data/pumpkin_book.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': '', 'page': 150, 'producer': 'xdvipdfmx (20200315)', 'source': 'data/pumpkin_book.pdf', 'subject': '', 'title': '', 'total_pages': 196, 'trapped': ''}, page_content='•研究某任务在什么样的条件下可学得较好的模型？（定义12.2）•某算法在什么样的条件下可进行有效的学习?（定义12.3）•需多少训练样例才能获得较好的模型？（定义12.4）有限假设空间指H中包含的假设个数是有限的,反之则为无限假设空间;无限假设空间更为常见,例如能够将图5.4(a)(b)(c)中的正例和反例样本分开的线性超平面个数是无限多的。12.2.1式(12.9)的解释PAC辨识的定义：E(h)表示算法L在用观测集D训练后输出的假设函数h，它的泛化误差(见公式12.1)。这个概率定义指出，如果h的泛化误差不大于ϵ的概率不小于1−δ，那么我们称学习算法L能从假设空间H中PAC辨识概念类C。12.3有限假设空间本节内容分两部分,第1部分“可分情形”时,可以达到经验误差bE(h)=0,做的事情是以1−δ概率学得目标概念的ϵ近似,即式(12.12);第2部分“不可分情形”时,无法达到经验误差bE(h)=0,做的事情是以1−δ概率学得minh∈HE(h)的ϵ近似,即式(12.20)。无论哪种情形,对于h∈H,可以得到该假设的泛化误差E(h)与经验误差bE(h)的关系,即“当样例数目m较大时,')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 效果测评"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于已经生成的QA数据集进行评测，由于HyDE需要生成问题，因此存在一定程度的token使用，我们这里使用前50个问题进行实验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:06<00:00,  7.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# 不实用HyDE召回率\n",
    "from tqdm import tqdm\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for qa_pair in tqdm(qa_pairs[:50]):\n",
    "    if len(qa_pair['query']) > 10:\n",
    "        query = qa_pair['query']\n",
    "        sim_docs = retriever.vectorstore.similarity_search(query, k=5)\n",
    "        page_nums = [doc.metadata['page'] for doc in sim_docs]\n",
    "        if qa_pair['page_num'] in page_nums: i += 1\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "召回率为: 71.73913043478261%\n"
     ]
    }
   ],
   "source": [
    "print(f\"召回率为: {i/j * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:40<00:00,  3.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for qa_pair in tqdm(qa_pairs[:50]):\n",
    "    if len(qa_pair['query']) > 10:\n",
    "        query = qa_pair['query']\n",
    "        sim_docs, hypothetical_doc = retriever.retrieve(query)\n",
    "        page_nums = [doc.metadata['page'] for doc in sim_docs]\n",
    "        if qa_pair['page_num'] in page_nums: i += 1\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "召回率为: 73.91304347826086%\n"
     ]
    }
   ],
   "source": [
    "print(f\"召回率为: {i/j * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
